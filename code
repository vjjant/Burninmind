# -*- coding: utf-8 -*-
import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import datasets, metrics
from sklearn.preprocessing import binarize, LabelEncoder, MinMaxScaler
from sklearn.linear_model import LogisticRegression
import matplotlib
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import pyplot as plt
from matplotlib import cm as cm
import seaborn as sns
from sklearn.metrics import classification_report
import statsmodels.api as sm
from sklearn import preprocessing
from sklearn.datasets import make_classification
from sklearn.preprocessing import binarize, LabelEncoder, MinMaxScaler

data = r'C:\Users\kvanh\Desktop\survey.xlsx'
data2 = r'C:\Users\kvanh\Desktop\book5.xlsx'
dataset_1 =pd.read_excel(data)
dataset_2 =pd.read_excel(data2)

#Clean age
maxlgn=len(dataset_1.loc[:,'Age'])
for i in range(0,maxlgn):
    if (int(dataset_1.loc[i,'Age'])<18 or int(dataset_1.loc[i,'Age'])>65):
        dataset_1.loc[i,'Age']= None
        i += 1
    else:
        i += 1

#complete missing age with mean
dataset_1['Age'].fillna(dataset_1['Age'].median(), inplace = True)

# Fill with median values < 18 and > 65
s = pd.Series(dataset_1['Age'])
s[s<18] = dataset_1['Age'].median()
dataset_1['Age'] = s
s = pd.Series(dataset_1['Age'])
s[s>120] = dataset_1['Age'].median()
dataset_1['Age'] = s

s1 = pd.Series(dataset_2['Age'])
s1[s1<18] = dataset_2['Age'].median()
dataset_2['Age'] = s1
s1 = pd.Series(dataset_2['Age'])
s1[s1>120] = dataset_2['Age'].median()
dataset_2['Age'] = s1

#Ranges of Age
dataset_1['age_range'] = pd.cut(dataset_1['Age'], [0,20,30,65], labels=["0-20", "21-30", "31-65"], include_lowest=True)
dataset_2['age_range'] = pd.cut(dataset_2['Age'], [0,20,30,65], labels=["0-20", "21-30", "31-65"], include_lowest=True)

#Clean gender        
maxlgn=len(dataset_1.loc[:,'Gender'])
ListF=['fem','female','Femail','f','femake', 'woman', 'Female', 'Femake']
for i in range(0,maxlgn):
    if (str(dataset_1.loc[i,'Gender']).lower()) in ListF:
        dataset_1.loc[i,'Gender']='F'
        i += 1
    else:
        i += 1

maxlgn=len(dataset_1.loc[:,'Gender'])
ListM=['men', 'man', 'male', 'Male', 'M', 'Mail']
for i in range(0,maxlgn):
    if (str(dataset_1.loc[i,'Gender']).lower()) in ListM:
        dataset_1.loc[i,'Gender']='M'
        i += 1
    else:
        i += 1

maxlgn=len(dataset_1.loc[:,'Gender'])
ListG=['M','F']
for i in range(0,maxlgn):
    if str(dataset_1.loc[i,'Gender']) not in ListG:
        dataset_1.loc[i,'Gender']='Other'
        i += 1
    else:
        i += 1

#drop unnecessary columns
dataset_1 = dataset_1.drop(['comments'], axis=1)
dataset_1 = dataset_1.drop(['Timestamp'], axis=1)
dataset_1 = dataset_1.drop(['Country'], axis=1)
dataset_1 = dataset_1.drop(['state'], axis=1)

dataset_2 = dataset_2.drop(['comments'], axis=1)
dataset_2 = dataset_2.drop(['Timestamp'], axis=1)
dataset_2 = dataset_2.drop(['Country'], axis=1)
dataset_2 = dataset_2.drop(['state'], axis=1)

# Assign default values for each data type
defaultInt = 0
defaultString = 'NaN'
defaultFloat = 0.0

# Create lists by data tpe
intFeatures = ['Age']
stringFeatures = ['Gender', 'self_employed', 'family_history', 'treatment', 'work_interfere',
                 'no_employees', 'remote_work', 'tech_company', 'anonymity', 'leave', 'mental_health_consequence',
                 'phys_health_consequence', 'coworkers', 'supervisor', 'mental_health_interview', 'phys_health_interview',
                 'mental_vs_physical', 'obs_consequence', 'benefits', 'care_options', 'wellness_program',
                 'seek_help']
floatFeatures = []

#factorizing columns
dataset_1.Gender = pd.factorize(dataset_1.Gender)[0]
dataset_1.self_employed = pd.factorize(dataset_1.self_employed)[0]
dataset_1.family_history = pd.factorize(dataset_1.family_history)[0]
dataset_1.treatment = pd.factorize(dataset_1.treatment)[0]
dataset_1.work_interfere = pd.factorize(dataset_1.work_interfere)[0]
dataset_1.no_employees = pd.factorize(dataset_1.no_employees)[0]
dataset_1.remote_work = pd.factorize(dataset_1.remote_work)[0]
dataset_1.tech_company = pd.factorize(dataset_1.tech_company)[0]
dataset_1.benefits = pd.factorize(dataset_1.benefits)[0]
dataset_1.care_options = pd.factorize(dataset_1.care_options)[0]
dataset_1.wellness_program = pd.factorize(dataset_1.wellness_program)[0]
dataset_1.seek_help = pd.factorize(dataset_1.seek_help)[0]
dataset_1.anonymity = pd.factorize(dataset_1.anonymity)[0]
dataset_1.leave = pd.factorize(dataset_1.leave)[0]
dataset_1.mental_health_consequence = pd.factorize(dataset_1.mental_health_consequence)[0]
dataset_1.phys_health_consequence = pd.factorize(dataset_1.phys_health_consequence)[0]
dataset_1.coworkers = pd.factorize(dataset_1.coworkers)[0]
dataset_1.supervisor = pd.factorize(dataset_1.supervisor)[0]
dataset_1.mental_health_interview = pd.factorize(dataset_1.mental_health_interview)[0]
dataset_1.phys_health_interview = pd.factorize(dataset_1.phys_health_interview)[0]
dataset_1.mental_vs_physical = pd.factorize(dataset_1.mental_vs_physical)[0]
dataset_1.obs_consequence = pd.factorize(dataset_1.obs_consequence)[0]
dataset_1.age_range = pd.factorize(dataset_1.age_range)[0]

dataset_2.Gender = pd.factorize(dataset_2.Gender)[0]
dataset_2.self_employed = pd.factorize(dataset_2.self_employed)[0]
dataset_2.family_history = pd.factorize(dataset_2.family_history)[0]
dataset_2.work_interfere = pd.factorize(dataset_2.work_interfere)[0]
dataset_2.no_employees = pd.factorize(dataset_2.no_employees)[0]
dataset_2.remote_work = pd.factorize(dataset_2.remote_work)[0]
dataset_2.tech_company = pd.factorize(dataset_2.tech_company)[0]
dataset_2.benefits = pd.factorize(dataset_2.benefits)[0]
dataset_2.care_options = pd.factorize(dataset_2.care_options)[0]
dataset_2.wellness_program = pd.factorize(dataset_2.wellness_program)[0]
dataset_2.seek_help = pd.factorize(dataset_2.seek_help)[0]
dataset_2.anonymity = pd.factorize(dataset_2.anonymity)[0]
dataset_2.leave = pd.factorize(dataset_2.leave)[0]
dataset_2.mental_health_consequence = pd.factorize(dataset_2.mental_health_consequence)[0]
dataset_2.phys_health_consequence = pd.factorize(dataset_2.phys_health_consequence)[0]
dataset_2.coworkers = pd.factorize(dataset_2.coworkers)[0]
dataset_2.supervisor = pd.factorize(dataset_2.supervisor)[0]
dataset_2.mental_health_interview = pd.factorize(dataset_2.mental_health_interview)[0]
dataset_2.phys_health_interview = pd.factorize(dataset_2.phys_health_interview)[0]
dataset_2.mental_vs_physical = pd.factorize(dataset_2.mental_vs_physical)[0]
dataset_2.obs_consequence = pd.factorize(dataset_2.obs_consequence)[0]
dataset_2.age_range = pd.factorize(dataset_2.age_range)[0]

# Scaling Age
scaler = MinMaxScaler()
dataset_1['Age'] = scaler.fit_transform(dataset_1[['Age']])
dataset_2['Age'] = scaler.fit_transform(dataset_2[['Age']])

# pre-processing correlation map
k = 24
corrmat = dataset_1.corr()
cols = corrmat.nlargest(k, 'treatment')['treatment'].index
cor = np.corrcoef(dataset_1[cols].values.T)
sns.set(font_scale=1.25)
hm = sns.heatmap(cor, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)
plt.show()

X = dataset_1.loc[:,dataset_1.columns !="treatment"]
y = dataset_1.treatment

# split X and y into training and testing sets
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = 0)

# train a logistic regression model on the training set
logreg = LogisticRegression()
logreg.fit(X, y)
y_pred = logreg.predict(X_test)

# accuracy score    
from sklearn.linear_model import LogisticRegressionCV
clf = LogisticRegressionCV(cv=5, random_state=0,
                    multi_class='multinomial').fit(X, y)
clf.score(X, y)

#classification report
from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))

#statsmodel
import statsmodels.api as sm
import statsmodels.formula.api as sm
logit_model=sm.Logit(y,X)
result=logit_model.fit()
print(result.summary())

#probability 
g = sns.factorplot(x="age_range", y="treatment",hue="Gender",data=dataset_1, kind="bar",  ci=None, size=5, aspect=2, legend_out = True)
g.set_xticklabels(o)
plt.title('Probability of mental health condition')
plt.ylabel('Probability x 100')
plt.xlabel('age_range')

#Naves bayes
from sklearn.naive_bayes import GaussianNB
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import cross_val_score
clf = make_pipeline(preprocessing.StandardScaler(), GaussianNB(priors=None))
np.mean(cross_val_score(clf,X,y, cv=10))

#Confusion matrix
confusion = metrics.confusion_matrix(y_test, y_pred)
tp = confusion[1, 1]
fp = confusion[0, 1]
fn = confusion[1, 0]
tn = confusion[0, 0]
 
sns.heatmap(confusion,annot=True,fmt="d") 
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

#single class addition
xnew = dataset_2.loc[:,dataset_2.columns !="treatment"] 
ynew = logreg.predict_proba(xnew)
for i in range(len(xnew)):
print(ynew[i])
